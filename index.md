---
layout: page
title: ""
---

<div style="display: flex; align-items: center;">
  <img src="/assets/IMG_0790.jpeg" alt="Hyunin Lee" style="width: 25%; height: auto; border: 2px solid black; border-radius: 15px; margin-right: 20px;">
  <div>
    <h2 style="margin: 0;">Hyunin Lee</h2>
    <p style="margin: 0;">Ph.D at UC Berkeley</p>
    <p><strong>Contact:</strong> hyunin(at)berkeley(dot)edu</p>
    <p><strong>Research Interests:</strong> Reinforcment Learning </p>
    <p>
      <a href="./assets/CV_update.pdf" target="_blank">
        <img src="/assets/CV2.svg" alt="CV" style="width: auto; height: 30px; margin-right: 15px;">
      </a>
      <a href="https://scholar.google.com/citations?user=kHTDu1YAAAAJ&hl=en" target="_blank">
        <img src="/assets/googlescholar.svg" alt="Google Scholar" style="width: auto; height: 30px; margin-right: 15px;">
      </a>
      <a href="https://kr.linkedin.com/in/hyunin-lee-539b641b1" target="_blank">
        <img src="/assets/linkedin.svg" alt="LinkedIn" style="width: auto; height: 30px; margin-right: 15px;">
      </a>
      <a href="https://github.com/hyunin-lee" target="_blank">
        <img src="/assets/github.svg" alt="GitHub" style="width: auto; height: 30px;">
      </a>
    </p>
  </div>
</div>

<!-- 
    <p>
      <a href="https://scholar.google.com/citations?user=kHTDu1YAAAAJ&hl=en">Google Scholar</a> /
      <a href="https://kr.linkedin.com/in/hyunin-lee-539b641b1">LinkedIn</a> /
      <a href="https://github.com/hyunin-lee">GitHub</a>
    </p>
-->


<!--
<div style="display: flex; align-items: center;">
  <div style="width: 30%; height: auto; overflow: hidden; border: 2px solid black; border-radius: 15px; display: flex; justify-content: center; align-items: center;">
    <img src="/assets/hyunin2.jpg" alt="Hyunin Lee" style="width: 100%; height: auto; object-fit: cover;">
  </div>
  <div style="margin-left: 20px;">
    <h2 style="margin: 0;">Hyunin Lee</h2>
    <p style="margin: 0;">Ph.D at UC Berkeley & co-founder of OUTTA </p>
    <p><strong>Contact:</strong> hyunin(at)berkeley(dot)edu</p>
    <p><strong>Research Interests:</strong> Reinforcment Learning </p>
  </div>
</div>
-->
### About
I am Hyunin Lee, a fourth-year Ph.D. candidate at UC Berkeley. I am interested in **developing reinforcement learning algorithms and exploring their key concepts**. I am fortunate to work with [Somayeh Sojoudi](https://people.eecs.berkeley.edu/~sojoudi/index.html). Prior to joining Berkeley, I received my B.S. degree from Seoul National University where I have worked on research projects within neuroscience and machine learning with [Yong-Lae Park](https://softrobotics.snu.ac.kr/). 

Besides my research, I am interested in AI education üìöüë©üèª‚Äçüíª. I cofound and currently advise [OUTTA](https://outta.ai/).

<!--
### Research questions
* Identifying Challenges Beyond Scaling: What fundamental problems remain unsolvable despite scaling up models and data?
* Human-Centered AI Representation: How can we translate intangible challenges from human environments into tractable decision-making formulations?
-->
### Research Area
* Reinforcement Learning, Multi-Modal Learning

<!-- ### Questions.
* Currently, I‚Äôm curious about the following questions:
  * Why are many traditional exploration methods in RL not working in LLM post-training?
  * Black swan events in AI safety: [1](https://arxiv.org/pdf/2407.18422), [2](https://openreview.net/pdf?id=WpePuya3Ki)
  * Orthogonal alignment in vision-language model: [1](https://arxiv.org/abs/2510.09435) -->

### Blog
 * [An Orthogonal Alignment Phenomenon in Cross-Attention](https://hyunin-lee.github.io/An-Orthogonal-Alignment-Phenomenon-in-Cross-Attention/)

### News 
* [2026.01] Started a research collaboration with [SakanaAI](https://sakana.ai/) <img src="https://sakana.ai/favicon.ico" alt="SakanaAI" style="height: 15px; vertical-align: middle; margin-left: 1px;"> on agentic AI workflows.
* [2026.01] My research will be further funded by Meta for personalization in multimodal models.
* [2025.10] New paper on Multi-Modal Learning (work done during Meta internship): [*Orthogonal Alignment*](https://arxiv.org/abs/2510.09435) and its blog post: [*An Orthogonal Alignment Phenomenon in Cross-Attention*](https://hyunin-lee.github.io/An-Orthogonal-Alignment-Phenomenon-in-Cross-Attention/)
* [2025.06] Extension of Black swan paper: [*Antifragile*](https://openreview.net/pdf?id=WpePuya3Ki) will be presented in **ICML2025**.
* [2025.05] Joining [Meta](https://ai.meta.com/) <img src="https://upload.wikimedia.org/wikipedia/commons/0/05/Meta_Platforms_Inc._logo_%28cropped%29.svg" alt="Meta" style="height: 13px; vertical-align: middle; margin-left: 1px;"> this summer as a research scientist intern (Ranking team)! 
* [2025.04] [*Black Swan Hypothesis* ü¶¢](https://arxiv.org/pdf/2407.18422) as <span style="color:red;"><b>oral</b></span> presentation at **ICLR25 workshop: Financial AI**
* [2025.04] Invited to AI safety panel at [Appen](https://www.appen.com/)
* [2025.03] Started research associate with [OpenAI](https://openai.com/safety/) <img src="https://upload.wikimedia.org/wikipedia/commons/6/66/OpenAI_logo_2025_%28symbol%29.svg" alt="OpenAI" style="height: 15px; vertical-align: middle; margin-left: 1px;">
* [2025.02] New paper on proposing the necessity of antifragility in AI safety : [*Antifragile*](https://openreview.net/pdf?id=WpePuya3Ki)
* [2024.02] Serving as a reviewer for ICML, RLC, and Neurips 2025.
* [2025.01] New paper proposing a novel AI safety perspective, *Black Swan Hypothesis* ü¶¢, in **ICLR2025** (& workshop: Financial AI 25): [A Black Swan Hypothesis: The Role of Human Irrationality in AI Safety](https://arxiv.org/pdf/2407.18422)
* [2024.09] Serving as a reviewer for ICLR, AISTATS 2025.
* [2024.07] Attending RLC.
* [2024.07] Serving on the program chair committee for AAAI 2025.  
<!-- * [2024.07] New paper on reinforcement Learning: [A Black Swan Hypothesis: The Role of Human Irrationality in AI Safetys](./assets/blackswanHumanMDP.pdf) -->
* [2024.05] New paper on Safe reinforcement Learning: [Policy-based Primal-Dual Methods for Concave CMDP with Variance Reduction](./assets/convexCMDP.pdf)
* [2024.05] New paper on optimal early stopping of non-stationary Reinforcement Learning in **ICML 2024** <span style="color:red;"><b>(Oral, top 1%)</b></span>: [Pausing Policy Learning in Non-stationary Reinforcement Learning](./assets/ICML2024RL_hyunin.pdf). [[Talk](https://icml.cc/virtual/2024/session/35272)/[codes](https://github.com/hyunin-lee/ForecasterSAC)]
* [2024.04] Received a Berkeley research fellowship.
* [2024.03] Served as a reviewer for ICML 2024.
* [2024.02] New paper on proposing new policy gradient estimator in reinforcement Learning in **IEEE TAC**: [Beyond Exact Gradients: Convergence of Stochastic
Soft-Max Policy Gradient Methods with Entropy Regularization](./assets/TAC_Entropy_SPG.pdf).
* [2023.10] Received a NeurIPS scholar award
* [2023.08] OUTTA has launched a new spinoff team, **AI PLAYGROUND**, dedicated to creating intuitive AI educational materials for elementary education! I lead the team. 
* [2023.05] New paper on proposing *Tempo* in Non-stationary Reinforcement Learning in **NeurIPS 2023**: [Tempo Adaption in Non-stationary Reinforcement Learning](./assets/TempoAdaption_NSRL.pdf). [[slides](./assets/TempoAdaption_NSRL_slides.pdf)] [[codes](https://github.com/hyunin-lee/TempoRL)]
* [2023.01] New paper on Causal Machine Learning in **CDC 2023**: [Initial State Interventions for Deconfounded Imitation Learning](https://sam.pfrommer.us/wp-content/uploads/2023/03/main.pdf).
* [2022.08] I started Ph.D. at UC Berkeley.
* [2022.05] Received the Kwanjeong Education Foundation Scholarship.
* [2022.03] New paper on Neuroscience and Machine Learning in **IEEE TNSRE**: [Explainable Deep Learning Model for EMG-Based Finger Angle Estimation using Attention](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9829861). [[slides](./assets/Explainable_EMG.pdf)] [[videos](https://www.youtube.com/watch?v=yYV5koXMPzo)] [[codes](https://github.com/hyunin-lee/AttentionEMG)]
* [2022] I have co-founded üöÄ[**OUTTA**](https://outta.ai/)üöÄ with [Haeun (MIT)](https://www.linkedin.com/in/david-ha-eun-kang-78b932132/), [Chankyo (UMich)](https://www.linkedin.com/in/chankyo-kim-603592238/)

### Education 
* Ph.D., University of California, Berkeley, 2022.08 - current
* B.S., Seoul National University, 2015.03 - 2022.02  
  (Served military service in Korean Combat Traning Center, 2017.07 - 2019.03)

