---
title:  "Deep learning theoery 1.pretraining"
mathjax: true
layout: post
categories: media
---
The most important principle: wide and deep neural networks are governed by nearly-Gaussian distributions.
### [1.1] Gaussian integrals.
* single variable gaussian distribution
    - Gaussian distributions with zero-mean & variance K : $$ e^{i\theta}=\cos(\theta)+i\sin(\theta) $$
    - Expectation values of general functions $\mathcal{O}(z)$ (observable function) when $z$ follows the gaussian distribution.
$$ e^{i\theta}=\cos(\theta)+i\sin(\theta) $$




